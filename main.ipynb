{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get Info's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get comment's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_comments(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param url: the url from foxsports site with the commentaries\n",
    "    :return: return a Data Frame after concat the input df and info's of url\n",
    "    \"\"\"\n",
    "    # make a get in url of game and save the page source to work\n",
    "    dict_names = {'1. FC Köln': 'FC Koln', '1. FC Union Berlin': 'Union Berlin', '1899 Hoffenheim': 'Hoffenheim',\n",
    "                  'Bayer Leverkusen': 'Bayer Leverkusen', 'Bayern Munich': 'Bayern Munich',\n",
    "                  'Borussia Dortmund': 'Dortmund',\n",
    "                  'Eintracht Frankfurt': 'Eintracht Frankfurt', 'FC Augsburg': 'Augsburg', 'FC Schalke 04': 'Schalke',\n",
    "                  'FSV Mainz 05': 'Mainz', 'Fortuna Düsseldorf': 'Dusseldorf', 'Hertha BSC Berlin': 'Hertha Berlin',\n",
    "                  'Mönchengladbach': 'B. Monchengladbach', 'RB Leipzig': 'RB Leipzig', 'SC Freiburg': 'Freiburg',\n",
    "                  'SC Paderborn': 'Paderborn', 'VfL Wolfsburg': 'Wolfsburg', 'Werder Bremen': 'Werder Bremen'}\n",
    "    path_crome = 'C:/Users/pedro/selenium/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(executable_path=path_crome)\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"fullCommentary\"]')))\n",
    "    element = driver.find_element_by_id('fullCommentary')\n",
    "    driver.execute_script(\"arguments[0].click();\", element)\n",
    "    html = driver.page_source\n",
    "    # read the html with BeautifulSoup and get the name of teams\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    home = soup.find_all('span', {'class': 'wisbb_bsName'})[0].text\n",
    "    home = dict_names[home]\n",
    "    away = soup.find_all('span', {'class': 'wisbb_bsName'})[1].text\n",
    "    away=dict_names[away]\n",
    "    home_goals_final = int(soup.find_all('td', {'class': 'wisbb_bsTotal'})[0].text.strip())\n",
    "    away_goals_final = int(soup.find_all('td', {'class': 'wisbb_bsTotal'})[1].text.strip())\n",
    "    # save all commentaries in one list to work, and set the home image to select what team is the commentary\n",
    "    commentaries = soup.find('table', {'class': 'wisbb_bsCPbpSmallTable'}).find_all('tr')\n",
    "    img_home = commentaries[0].find('img')['src']\n",
    "    # make empty lists, and work in each commentary to save commentary, team, and time of commentary\n",
    "    urls, time, team, comm = [], [], [], []\n",
    "    for comments in commentaries:\n",
    "        urls.append(url)\n",
    "        time_aux = comments.find('td', {'class': 'wisbb_bsSoccerPbpTimeCol'}).text.replace(\"'\", '').split('+')\n",
    "        time.append(sum([int(item) for item in time_aux]))\n",
    "        team.append(home if comments.find('img')['src'] == img_home else away)\n",
    "        comm.append(comments.find('span', {'class': 'wisbb_bsSoccerPbpDesc'}).text)\n",
    "    infos = {'url': urls,'home_team':home, 'away_team':away, 'time': time, 'team': team,\n",
    "             'home_goals_final': home_goals_final, 'away_goals_final' : away_goals_final, 'comm': comm}\n",
    "    # save infos in Data Frame and concat with previous Data Frame\n",
    "    df_aux = pd.DataFrame(infos)\n",
    "    driver.quit()\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get statistcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_stats_game(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    With the selenium web driver, open a url get stats of a game and append in Data Frame the stats of game\n",
    "    :param driver: Web driver from selenium\n",
    "    :param url: link with de stats we want to scraping\n",
    "    :param df: Data Frame with storage values\n",
    "    :return: Data frame append new values\n",
    "    \"\"\"\n",
    "    # make a driver to create a section were we going to work, and get the page source\n",
    "    path_crome = 'C:/Users/pedro/selenium/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(executable_path=path_crome)\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"summary-content\"]/div[1]/div[3]/div[2]/span[1]')))\n",
    "    time.sleep(2)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # get infos with main page\n",
    "    infos = {}\n",
    "    infos['url'] = url\n",
    "    infos['round'] = int(soup.find('span', {'class': 'description__country'}).text.split(' ')[-1])\n",
    "    infos['home_team'] = soup.find('div', {'class': 'tname__text'}).text.strip()\n",
    "    infos['away_team'] = soup.find_all('div', {'class': 'tname__text'})[1].text.strip()\n",
    "    infos['goals_home_final'] = int(soup.find('span', {'class': 'scoreboard'}).text)\n",
    "    infos['goals_away_final'] = int(soup.find_all('span', {'class': 'scoreboard'})[1].text)\n",
    "    infos['final_result'] = 'Away' if infos['goals_home_final'] < infos['goals_away_final'] else 'Home' if infos[\n",
    "                                                                                                               'goals_home_final'] > \\\n",
    "                                                                                                           infos[\n",
    "                                                                                                               'goals_away_final'] else 'Draw'\n",
    "    infos['goals_home_1half'] = int(soup.find('span', {'class': 'p1_home'}).text)\n",
    "    infos['goals_away_1half'] = int(soup.find('span', {'class': 'p1_away'}).text)\n",
    "    infos['1half_result'] = 'Away' if infos['goals_home_1half'] < infos['goals_away_1half'] else 'Home' if infos[\n",
    "                                                                                                               'goals_home_1half'] > \\\n",
    "                                                                                                           infos[\n",
    "                                                                                                               'goals_away_1half'] else 'Draw'\n",
    "    # change page to statistic in first half, and get info's\n",
    "    WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"a-match-statistics\"]'))).click()\n",
    "    WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"statistics-1-statistic\"]/span/a'))).click()\n",
    "    time.sleep(2)\n",
    "    # get body info with text and make a list by info\n",
    "    html_code = driver.find_element_by_tag_name(\"body\").text.split('\\n')\n",
    "    # set first info Ball Possession and, make a while to end into last info dangerous_attacks\n",
    "    i = 0\n",
    "    x = html_code.index('Ball possession')\n",
    "    stat = html_code[x + i * 3].lower().replace(' ', '_')\n",
    "    while stat != 'dangerous_attacks':\n",
    "        stat = html_code[x + i * 3].lower().replace(' ', '_')\n",
    "        if stat not in ['throw_ins', 'completed_passes']:\n",
    "            infos[stat + 'home'] = int(html_code[x + i * 3 - 1].replace('%', ''))\n",
    "            infos[stat + 'away'] = int(html_code[x + i * 3 + 1].replace('%', ''))\n",
    "        i += 1\n",
    "    # make a aux Data Frame, concat the data to previous Data Frame and return a Data Frame\n",
    "    df_aux = pd.DataFrame(infos, index=[0])\n",
    "    if 'yellow_cardshome' not in list(df_aux.columns):\n",
    "        df_aux['yellow_cardshome'] = 0\n",
    "        df_aux['yellow_cardsaway'] = 0\n",
    "    if 'red_cardshome' not in list(df_aux.columns):\n",
    "        df_aux['red_cardshome'] = 0\n",
    "        df_aux['red_cardsaway'] = 0\n",
    "    driver.quit()\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Transform comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transform_comments(df):\n",
    "    df.drop(columns=['url'], inplace= True)\n",
    "    with open ('C:/Users/pedro/Projetos/bundesbet/models/commentaries/words.p', 'rb') as fp:\n",
    "        my_words = pickle.load(fp)\n",
    "    X = list(df['comm'])\n",
    "    dataprep = Pipeline([('count_vectorizer', CountVectorizer(ngram_range=(1,3), min_df=1, stop_words=my_words))])\n",
    "    n_com=5\n",
    "    pipeline = Pipeline([\n",
    "        ('dataprep', dataprep),\n",
    "        ('topic_modelling', LatentDirichletAllocation(n_components=n_com, random_state=42,n_jobs=-1))])\n",
    "    pipeline.fit(X)\n",
    "    topic_values = pipeline.transform(X)\n",
    "    df['labels'] = topic_values.argmax(axis=1)\n",
    "    def who_wins(row):\n",
    "        result = 'Away' if row['home_goals_final'] < row['away_goals_final'] else 'Home' if row['home_goals_final'] >row['away_goals_final'] else 'Draw'\n",
    "        return result\n",
    "    df['result']= df.apply(lambda row: who_wins(row), axis=1)\n",
    "    df.drop(columns=['home_goals_final','away_goals_final'], inplace=True)\n",
    "    X=pd.get_dummies(df, columns=['labels'])\n",
    "    df_group=X.groupby(['team','result']).sum().reset_index()\n",
    "    df_group.drop(columns=['time'],inplace= True)\n",
    "    df_home=pd.DataFrame(df_group.iloc[1,:]).T\n",
    "    home_columns= ['labels_'+str(i)+'_home' for i in np.arange(0,n_com)]\n",
    "    home_columns=['team_home','result']+home_columns\n",
    "    df_home.columns=home_columns\n",
    "    df_away=pd.DataFrame(df_group.iloc[0,:]).T\n",
    "    away_columns= ['labels_'+str(i)+'_away' for i in np.arange(0,n_com)]\n",
    "    away_columns=['team_away','result']+away_columns\n",
    "    df_away.columns=away_columns\n",
    "    df_result=pd.merge(left=df_home, right=df_away, on=['result'])\n",
    "    def func(x):\n",
    "        \"\"\"\n",
    "        Applying a function that change values of a Draw Match to 0, when Home team won to 1 and Away team won to -1.\n",
    "        \"\"\"\n",
    "        if x == 'Draw':\n",
    "            return 0\n",
    "        elif x == 'Home':\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def apply_func(dataframe, column):\n",
    "        dataframe[column] = dataframe[column].apply(func)\n",
    "    apply_func(df_result, 'result')\n",
    "    df_final=df_result.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df_result[['team_home','team_away']] = df_result[['team_home','team_away']].apply(le.fit_transform)\n",
    "    model_lda = pickle.load(open('C:/Users/pedro/Projetos/bundesbet/models/commentaries/ldamodel.sav', 'rb'))\n",
    "    X=df_result.drop(columns=['result'])\n",
    "    proba= model_lda.predict_proba(X)\n",
    "    df_final['proba_home']=proba[:,2]\n",
    "    df_final['proba_draw']=proba[:,1]\n",
    "    df_final['proba_away']=proba[:,0]\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Transform stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transform_stats(df):\n",
    "    def func(x):\n",
    "        \"\"\"\n",
    "        Applying a function that change values of a Draw Match to 0, when Home team won to 1 and Away team won to -1.\n",
    "        \"\"\"\n",
    "        if x == 'Draw':\n",
    "            return 0\n",
    "        elif x == 'Home':\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def apply_func(dataframe, column_list):\n",
    "        for column in column_list:\n",
    "            dataframe[column] = dataframe[column].apply(func)\n",
    "    df_aux=df.copy()\n",
    "    df_aux.drop(columns=['url','round','final_result','goals_home_final', 'goals_away_final'], inplace= True)\n",
    "    list_result = ['1half_result']\n",
    "    apply_func(df_aux, list_result)\n",
    "    scaler = StandardScaler()\n",
    "    le = LabelEncoder()\n",
    "    df_aux[['home_team','away_team']] = df[['home_team','away_team']].apply(le.fit_transform)\n",
    "    model_stats = pickle.load(open('C:/Users/pedro/Projetos/bundesbet/models/game stats/game_stats_model.sav', 'rb'))\n",
    "    X=df_aux\n",
    "    df['proba_stats_home']=model_stats.predict_proba(X)[:,2]\n",
    "    df['proba_stats_draw']=model_stats.predict_proba(X)[:,1]\n",
    "    df['proba_stats_away']=model_stats.predict_proba(X)[:,0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stak Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stak(comments,stats):\n",
    "    columns=['home_team','away_team','proba_stats_home', 'proba_stats_draw', 'proba_stats_away']\n",
    "    stats=stats.loc[:,columns]\n",
    "    columns=['team_home','team_away','proba_home','proba_draw','proba_away']\n",
    "    comments=comments.loc[:,columns]\n",
    "    df=pd.concat([comments,stats], axis=1)\n",
    "    X_proba=df[['proba_draw','proba_stats_draw']]\n",
    "    model_draw = pickle.load(open('C:/Users/pedro/Projetos/bundesbet/models/stack/draw_model.sav', 'rb'))\n",
    "    draw_proba=model_draw.predict_proba(X_proba)[:,1]\n",
    "    X_proba=df[['proba_home','proba_stats_home']]\n",
    "    model_home = pickle.load(open('C:/Users/pedro/Projetos/bundesbet/models/stack/home_model.sav', 'rb'))\n",
    "    home_proba=model_home.predict_proba(X_proba)[:,1]\n",
    "    X_proba=df[['proba_away','proba_stats_away']]\n",
    "    model_away = pickle.load(open('C:/Users/pedro/Projetos/bundesbet/models/stack/away_model.sav', 'rb'))\n",
    "    away_proba=model_away.predict_proba(X_proba)[:,1]\n",
    "    infos={}\n",
    "    infos[df['home_team'].values[0]]=home_proba\n",
    "    infos['draw']=draw_proba\n",
    "    infos[df['away_team'].values[0]]=away_proba\n",
    "    return (pd.DataFrame(infos).round(2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stats(url_comments,url_stats):\n",
    "    comments_raw=get_comments(url_comments)\n",
    "    stats_raw=get_stats_game(url_stats)\n",
    "    comments=transform_comments(comments_raw)\n",
    "    stats=transform_stats(stats_raw)\n",
    "    return stak(comments,stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dortmund</th>\n",
       "      <th>draw</th>\n",
       "      <th>Schalke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dortmund  draw  Schalke\n",
       "0      72.0   9.0     36.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_stats='https://www.scoreboard.com/game/I9hb3B4S/#match-summary'\n",
    "url_comments='https://www.foxsports.com/soccer/boxscore?id=63353'\n",
    "find_stats(url_comments,url_stats)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
